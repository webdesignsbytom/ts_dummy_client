# https://www.robotstxt.org/robotstxt.html

User-agent: *
Allow: /

# Disallow web crawlers from accessing specific directories (if they exist)
Disallow: /admin/
Disallow: /user/

# Block specific bots
User-agent: BadBot
Disallow: /

# Sitemap location
Sitemap: https://www.client.com/sitemap.xml
